# -*- coding: utf-8 -*-
"""
.agent/skills/skills_evaluator.py
=====================================
ç”¨é€”ï¼šè§£æ Log ä¸­çš„ SKILLS_EXECUTION_REPORTï¼Œç”¢ç”Ÿçµ±è¨ˆå ±å‘Š
è·è²¬ï¼š
  - è§£æ Log è¡¨æ ¼ä¸¦å½™æ•´ç‹€æ…‹åˆ†å¸ƒèˆ‡æŠ€èƒ½åŸ·è¡Œæ¬¡æ•¸
  - è¼¸å‡º JSONï¼ˆé è¨­ï¼‰æˆ– Markdownï¼ˆ--format markdownï¼‰
=====================================

ä½¿ç”¨æ–¹å¼ï¼š
    python .agent/skills/skills_evaluator.py <log_file_path> [--format json|markdown]

è¼¸å‡ºï¼ˆJSONï¼‰ï¼š
    JSON æ ¼å¼å ±å‘Šï¼ˆstatus: pass|warning|errorï¼‰
é€€å‡ºç¢¼ï¼š
    0 = pass|warning
    2 = error
"""

from __future__ import annotations

import json
import re
import sys
from collections import Counter
from pathlib import Path
from typing import Any, Dict, List


def validate_output_schema(result: Dict[str, Any], skill_name: str) -> Dict[str, Any]:
    """å¯é¸ JSON Schema é©—è­‰ï¼ˆgraceful degradationï¼‰"""
    try:
        import jsonschema
    except ImportError:
        return result

    schema_path = Path(__file__).resolve().parent / "schemas" / f"{skill_name}_output.schema.json"
    if not schema_path.exists():
        return result

    try:
        schema = json.loads(schema_path.read_text(encoding="utf-8"))
        jsonschema.validate(result, schema)
        return result
    except jsonschema.ValidationError as exc:
        result["validation_errors"] = [
            {"message": exc.message, "path": list(exc.path), "schema_path": list(exc.schema_path)}
        ]
        result.setdefault(
            "suggestion",
            f"è¼¸å‡ºæ ¼å¼ä¸ç¬¦åˆ schema è¦ç¯„ã€‚è«‹æª¢æŸ¥ {skill_name}_output.schema.json ä¸¦ç¢ºèªæ¬„ä½æ­£ç¢ºæ€§ã€‚",
        )
        return result
    except Exception:
        return result


def _strip_ticks(value: str) -> str:
    v = value.strip()
    if v.startswith("`") and v.endswith("`") and len(v) >= 2:
        return v[1:-1].strip()
    return v


def parse_skills_execution_report(log_content: str) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    lines = log_content.splitlines()

    header_index = None
    for i, line in enumerate(lines):
        if line.strip().startswith("## ğŸ› ï¸ SKILLS_EXECUTION_REPORT"):
            header_index = i
            break

    if header_index is None:
        return records

    section_lines: List[str] = []
    for line in lines[header_index + 1 :]:
        if line.startswith("## "):
            break
        section_lines.append(line)

    for raw in section_lines:
        row = raw.strip()
        if not row.startswith("|"):
            continue
        parts = [p.strip() for p in row.strip("|").split("|")]
        if len(parts) < 5:
            continue
        skill, target, status, summary, timestamp = parts[:5]
        if skill.strip().lower() in {"skill", "---", ""}:
            continue
        if re.fullmatch(r"-{3,}", _strip_ticks(skill)):
            continue

        records.append(
            {
                "skill": _strip_ticks(skill),
                "target": _strip_ticks(target),
                "status": _strip_ticks(status).lower(),
                "summary": summary.strip(),
                "timestamp": timestamp.strip(),
            }
        )

    return records


def compute_statistics(records: List[Dict[str, Any]]) -> Dict[str, Any]:
    if not records:
        return {
            "total_executions": 0,
            "success_rate": 0.0,
            "status_distribution": {},
            "skill_counts": {},
            "failed_skills": [],
            "summary": "æœªæ‰¾åˆ° skills åŸ·è¡Œè¨˜éŒ„",
        }

    status_counter = Counter(r.get("status", "") for r in records)
    skill_counter = Counter(r.get("skill", "") for r in records)

    failed_skills = [
        {"skill": r.get("skill", ""), "target": r.get("target", ""), "summary": r.get("summary", "")}
        for r in records
        if r.get("status") in {"fail", "error"}
    ]

    success_count = (
        status_counter.get("pass", 0) + status_counter.get("warning", 0) + status_counter.get("no_tests", 0)
    )
    total_count = len(records)
    success_rate = (success_count / total_count * 100.0) if total_count else 0.0

    return {
        "total_executions": total_count,
        "success_rate": round(success_rate, 2),
        "status_distribution": dict(status_counter),
        "skill_counts": dict(skill_counter.most_common()),
        "failed_skills": failed_skills,
        "summary": f"{total_count} æ¬¡åŸ·è¡Œï¼ŒæˆåŠŸç‡ {success_rate:.1f}%",
    }


def generate_markdown_report(stats: Dict[str, Any]) -> str:
    md_lines: List[str] = []
    md_lines.append("# Skills Evaluation Report")
    md_lines.append("")
    md_lines.append(f"**ç¸½åŸ·è¡Œæ¬¡æ•¸**: {stats.get('total_executions', 0)}")
    md_lines.append(f"**æˆåŠŸç‡**: {stats.get('success_rate', 0.0)}%")
    md_lines.append("")

    md_lines.append("## Status åˆ†å¸ƒ")
    md_lines.append("")
    md_lines.append("| Status | Count |")
    md_lines.append("|--------|-------|")
    for status, count in (stats.get("status_distribution") or {}).items():
        md_lines.append(f"| {status} | {count} |")
    md_lines.append("")

    md_lines.append("## Skills åŸ·è¡Œæ¬¡æ•¸")
    md_lines.append("")
    md_lines.append("| Skill | Count |")
    md_lines.append("|-------|-------|")
    for skill, count in (stats.get("skill_counts") or {}).items():
        md_lines.append(f"| {skill} | {count} |")
    md_lines.append("")

    failed = stats.get("failed_skills") or []
    if failed:
        md_lines.append("## å¤±æ•—çš„ Skills")
        md_lines.append("")
        md_lines.append("| Skill | Target | Summary |")
        md_lines.append("|-------|--------|----------|")
        for item in failed:
            md_lines.append(f"| {item.get('skill','')} | {item.get('target','')} | {item.get('summary','')} |")
        md_lines.append("")

    return "\n".join(md_lines).rstrip() + "\n"


def _parse_format(argv: List[str]) -> str:
    if "--format" not in argv:
        return "json"
    try:
        idx = argv.index("--format")
        return argv[idx + 1].strip().lower()
    except Exception:
        return "json"


def main(argv: List[str]) -> int:
    usage = "python .agent/skills/skills_evaluator.py <log_file_path> [--format json|markdown]"

    if len(argv) < 2:
        result = {
            "status": "error",
            "log_path": "",
            "statistics": {},
            "message": "ç¼ºå°‘ Log æª”æ¡ˆè·¯å¾‘åƒæ•¸",
            "suggestion": "è«‹æä¾› Log æª”æ¡ˆè·¯å¾‘ï¼Œä¾‹å¦‚ï¼špython .agent/skills/skills_evaluator.py .agent/logs/Idx-012_log.mdï¼ˆworkflow/æ²»ç†ï¼‰æˆ– doc/logs/Idx-012_log.mdï¼ˆå°ˆæ¡ˆåŠŸèƒ½ï¼‰",
            "usage": usage,
        }
        result = validate_output_schema(result, "skills_evaluator")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return 2

    log_path = Path(argv[1])
    output_format = _parse_format(argv)

    if not log_path.exists():
        result = {
            "status": "error",
            "log_path": str(log_path),
            "statistics": {},
            "message": f"Log æª”æ¡ˆä¸å­˜åœ¨ï¼š{log_path}",
            "suggestion": "è«‹ç¢ºèªè·¯å¾‘æ­£ç¢ºï¼Œworkflow/æ²»ç†ä»»å‹™çš„ Log é€šå¸¸åœ¨ .agent/logsï¼›å°ˆæ¡ˆåŠŸèƒ½ä»»å‹™çš„ Log é€šå¸¸åœ¨ doc/logsã€‚",
            "usage": usage,
        }
        result = validate_output_schema(result, "skills_evaluator")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return 2

    try:
        log_content = log_path.read_text(encoding="utf-8")
    except Exception as exc:
        result = {
            "status": "error",
            "log_path": str(log_path),
            "statistics": {},
            "message": f"ç„¡æ³•è®€å– Log æª”æ¡ˆï¼š{exc}",
            "suggestion": "è«‹ç¢ºèªæª”æ¡ˆæ¬Šé™æ­£ç¢ºï¼Œæˆ–æ”¹ç”¨æ–‡å­—ç·¨è¼¯å™¨æª¢æŸ¥æª”æ¡ˆå…§å®¹ã€‚",
            "usage": usage,
        }
        result = validate_output_schema(result, "skills_evaluator")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return 2

    records = parse_skills_execution_report(log_content)
    if not records:
        result = {
            "status": "warning",
            "log_path": str(log_path),
            "statistics": {
                "total_executions": 0,
                "success_rate": 0.0,
                "status_distribution": {},
                "skill_counts": {},
                "failed_skills": [],
                "summary": "æœªæ‰¾åˆ° skills åŸ·è¡Œè¨˜éŒ„",
            },
            "message": "Log ä¸­æœªæ‰¾åˆ° SKILLS_EXECUTION_REPORT æ®µè½",
            "suggestion": "è«‹ç¢ºèª Log æª”æ¡ˆæ ¼å¼æ­£ç¢ºï¼Œæˆ–è£œä¸Š SKILLS_EXECUTION_REPORT è¡¨æ ¼å¾Œå†åŸ·è¡Œã€‚",
            "usage": usage,
        }
        result = validate_output_schema(result, "skills_evaluator")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return 0

    stats = compute_statistics(records)

    if output_format == "markdown":
        print(generate_markdown_report(stats), end="")
        return 0

    result = {"status": "pass", "log_path": str(log_path), "statistics": stats, "summary": stats.get("summary", "")}
    result = validate_output_schema(result, "skills_evaluator")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))
